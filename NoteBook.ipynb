{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sentiment analysis</h1>\n",
    "<ol>\n",
    "<h3><li>Définition du Sujet et Objectif</h3></li>\n",
    "<b>Sentiment analysis ?</b><br>\n",
    "<p>Aussi connue sous le nom de <strong><i>« Opinion Mining »</i></strong>, <strong>l’analyse des sentiments</strong> consiste à identifier les informations subjectives d’un texte pour <strong>extraire l’opinion de l’auteur</strong>. <br>\n",
    "De manière générale, <strong>l’analyse des sentiments</strong> permet de mesurer le niveau de satisfaction des clients vis-à-vis des produits ou services fournis par une entreprise ou un organisme. Elle peut même s’avérer <strong>bien plus efficace que des méthodes classiques</strong> comme les sondages puisque <strong>de nos jours, une partie croissante des consommateurs partage fréquemment leurs opinions sur les réseaux sociaux</strong>. </p>\n",
    "\n",
    "<p><i><strong>Objectif du Projet:</strong></i> Notre but est donc de mettre en place un modèle permettant de classifier les différents avis des clients d’un hôtel en deux classes qui sont : Avis positifs et avis négatifs.<br>\n",
    "Cette classification permettra au personnel de l’hôtel de pouvoir identifier les principales plaintes (Texte négatifs) afin d’améliorer leurs services et réduire le niveau d’insatisfaction des clients.<br></p>\n",
    "\n",
    "<h3><li>Constitution de la dataset</h3></li>\n",
    "<p>Avant d’entamer le travail proprement dit, nous allons d’abord décrire brièvement notre dataset.<br>\n",
    "Nous avons utilisé une dataset téléchargeable sur Kaggle via le lien suivant : \n",
    "<a href=\"https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews\">https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews</a><br></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Aperçu de la dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive parking got good deal sta...       1\n",
       "1  ok nothing special charge diamond member hilto...       0\n",
       "2  nice rooms not 4* experience hotel monaco seat...       1\n",
       "3  unique, great stay, wonderful time hotel monac...       1\n",
       "4  great stay great stay, went seahawk game aweso...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.to_csv('data.csv', index=False)  \n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En affichant le résumé de la dataset, on voit qu’elle contient 15 000 lignes et deux colonnes : <br>\n",
    "<ul>\n",
    "    <li>Une colonne Review : qui n’est autre qu’un paragraphe contenant le commentaire de l’utilisateur</li>\n",
    "    <li>Une colonne Rating : qui précise s’il s’agit d’un avis positif ou pas. Notre objectif principal est de détecter les avis négatifs donc la classe positive correspond aux avis négatifs qui et la classe négative correspond aux avis positifs.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20491 entries, 0 to 20490\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  20491 non-null  object\n",
      " 1   Rating  20491 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 320.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>En affichant les quantités de données pour chaque catégorie, on s’aperçoit qu’elle est disproportionnée. Elle contient plus d’avis positifs (environ 17000) que d’avis négatifs (environ 3000). Cette différence pourra sans doute influencer le modèle lors de l’entrainement. Ce dernier risque donc d’overfitter sur les avis positifs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17277\n",
       "0     3214\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour remédier à cela, il existe plusieurs possibilités :\n",
    "<ul>\n",
    "    <li><b>Sous-échantillonnage de la classe majoritaire</b> qui consiste à réduire le nombre d'échantillons de la classe majoritaire en sélectionnant au hasard un sous-ensemble de points de données de cette classe à utiliser pour la formation.</li>\n",
    "    <br>\n",
    "    <li><b>Suréchantillonnage de la classe minoritaire </b>qui consiste à augmenter le nombre d'échantillons de la classe minoritaire dans l'ensemble de données d'apprentissage. La méthode courante consiste à ajouter des copies de points de données de la classe minoritaire, ce qui amplifie la région de décision, ce qui améliore les métriques d'évaluation.</li>\n",
    "     <br>\n",
    "    <li>Faire du <b>webscraping</b> afin d’augmenter le nombre d’avis négatifs.</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "L'un des principaux inconvénients du sous-échantillonnage est que des données ou des informations utiles peuvent être perdues. De plus dans notre cas, on obtiendra en tout environ 6000 lignes de données, ce qui n’est pas vraiment approprié pour un problème de NLP.<br><br>\n",
    "Le principal inconvénient du suréchantillonnage est qu'elle peut entraîner un overfitting. <br><br>\n",
    "Nous allons donc opter pour la troisième solution qui est celle du webscraping.<br><br>\n",
    "Nous avons scrapper plusieurs sites différents. Les détails du webscraping se trouve dans le notebook <a href=\"scraping_data.py\"> webscraping.ipynb</a>. <br><br>\n",
    "Grâce au webscraping on a pu obtenir environ 5500 lignes avis négatifs. La dataset contient désormais 25000 données. Cette fois ci, en faisant un sous-échantillonnage, on obtient 17000 données en tout (8500 pour chaque catégorie)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que cela est fait, Notre dataset est constitué et on peut enchainer avec les étapes suivantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=\"3\">\n",
    "<h3><li>Plan de travail</h3></li>\n",
    "Comme on peut s’en douter, Il s’agit ici d’un problème de Natural Language Processing (NLP) ou Traitement automatique du langage naturel.<br>\n",
    "Et comme pour tout problème de NLP, Notre travail se compose principalement de deux parties :\n",
    "\n",
    "<ul>\n",
    "    <li>La partie <b>« linguistique »</b>, qui consiste à prétraiter et transformer les informations en entrée en un jeu de données exploitable.</li>\n",
    "    <li>La partie <b>« apprentissage automatique »</b>, qui porte sur l’application de modèles <b><i>de Machine Learning</i></b> à ce jeu de données.</li><br>\n",
    "</ul>\n",
    "Dans la suite du rapport, Nous allons aborder ces deux aspects, en décrivant brièvement les <b>principales méthodes utilisées </b>et en précisant les principaux défis auxquels nous avons fait face.\n",
    "</ol>\n",
    "<ol type=\"A\">\n",
    "<h3><li>Partie linguistique : Du texte à la donnée</li></h3>\n",
    "<p>Parmi les principales étapes de cette partie, on retrouve :</p>\n",
    "<ol type=\"a\">\n",
    "<li>Nettoyage : cette phase consiste à réaliser des tâches telles que la <b><i>suppression d’urls, d’emoji, suppression des chiffres, ponctuation, symboles et stopwords, passage en minuscule</i><b>.</li>\n",
    "</ol>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous les fonctions permettant de faire le nettoyage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/macbookpro/Documents/IMT-S8/ML/ProjetML-Sentiment_Analysis/NoteBook.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macbookpro/Documents/IMT-S8/ML/ProjetML-Sentiment_Analysis/NoteBook.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/IMT-S8/ML/ProjetML-Sentiment_Analysis/NoteBook.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macbookpro/Documents/IMT-S8/ML/ProjetML-Sentiment_Analysis/NoteBook.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstring\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_URL (text):\n",
    "    url = re.compile(r\"https?://\\s+ www\\.\\s+\")\n",
    "    return url.sub(r\"\", text)\n",
    "\n",
    "\n",
    "def remove_html(text):\n",
    "    html = re.compile(r\"<.*?>\")\n",
    "    return html.sub(r\"\", text)\n",
    "         \n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" # flags (i0s)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", string)\n",
    "\n",
    "\n",
    "def remove_punct (text):\n",
    "    table = str.maketrans (\"\",\"\",string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "stop = set (stopwords.words ( \"english\"))\n",
    "def remove_stopwords (text):\n",
    "    text = [word.lower () for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>On regroupe toutes ses fonctions en une seule appelée <i>nettoyerDataframe</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyerDataframe(df):\n",
    "    Review_cleaned = df.Review.map(lambda x: remove_URL(x))\n",
    "    Review_cleaned = Review_cleaned.map(lambda x: remove_html(x))\n",
    "    Review_cleaned = Review_cleaned.map(lambda x: remove_emoji(x))\n",
    "    Review_cleaned = Review_cleaned.map(lambda x: remove_punct(x)) \n",
    "    Review_cleaned = Review_cleaned.map(remove_stopwords)   \n",
    "    df.insert(1, \"Review_cleaned\", Review_cleaned)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite on applique cette fonction pour nettoyer la colonne « Review » et on stocke le résultat dans la colonne <i>« Review_cleaned »</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nettoyerDataframe(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(df.Review_cleaned)\n",
    "\n",
    "[ x for x in X.todense()[0][0:].tolist()[0] if x != 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "\n",
    "def afficherMetriques(y_test,y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f\"Accuracy : {accuracy * 100} %\")\n",
    "    print (f\"Précision {precision * 100} %\") \n",
    "    print (f\"Recall {recall * 100} %\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"Rating\"].values\n",
    "\n",
    "X_train , X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegression = LogisticRegression(multi_class='multinomial')\n",
    "logisticRegression.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logisticRegression.predict(X_test)\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : Regression logistique ******\")\n",
    "afficherMetriques(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naives Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussianNB = GaussianNB()\n",
    "gaussianNB.fit(X_train.toarray(),y_train)\n",
    "\n",
    "y_pred = logisticRegression.predict(X_test)\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : Naives Bayes ******\")\n",
    "afficherMetriques(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "\n",
    "svmModel = svm.SVC(kernel='linear') # Linear Kernel\n",
    "svmModel.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svmModel.predict(X_test)\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : SVM ******\")\n",
    "afficherMetriques(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "pac = PassiveAggressiveClassifier()\n",
    "pac.fit(X_train, y_train)\n",
    "\n",
    "ypred = pac.predict(X_test)\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : PAC ******\")\n",
    "afficherMetriques(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation croisée sur le modèle de regression logfistique\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rappels = cross_val_score(logisticRegression, X,y, cv=10,scoring='recall')\n",
    "rappels = pd.Series(rappels)\n",
    "print(\"Rappels : min=\",rappels.min(),\"  max=\",rappels.max(),\"  moyenne=\",rappels.mean())\n",
    "\n",
    "precisions = cross_val_score(logisticRegression, X,y, cv=10,scoring='precision')\n",
    "precisions = pd.Series(precisions)\n",
    "print(\"Precisions : min=\",precisions.min(),\"  max=\",precisions.max(),\"  moyenne=\",precisions.mean())\n",
    "\n",
    "accuracys = cross_val_score(logisticRegression, X,y, cv=10,scoring='accuracy')\n",
    "accuracys = pd.Series(accuracys)\n",
    "print(\"Accuracy : min=\",accuracys.min(),\"  max=\",accuracys.max(),\"  moyenne=\",accuracys.mean())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02a3c894954291fda4ab19733d35c869283f9a77a2dca789b03614318f65231a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('workshop': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
