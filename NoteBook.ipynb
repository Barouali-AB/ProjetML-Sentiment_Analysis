{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sentiment analysis</h1>\n",
    "<ol>\n",
    "<h3><li>Définition du Sujet et Objectif</h3></li>\n",
    "<b>Sentiment analysis ?</b><br>\n",
    "<p>Aussi connue sous le nom de <strong><i>« Opinion Mining »</i></strong>, <strong>l’analyse des sentiments</strong> consiste à identifier les informations subjectives d’un texte pour <strong>extraire l’opinion de l’auteur</strong>. <br>\n",
    "De manière générale, <strong>l’analyse des sentiments</strong> permet de mesurer le niveau de satisfaction des clients vis-à-vis des produits ou services fournis par une entreprise ou un organisme. Elle peut même s’avérer <strong>bien plus efficace que des méthodes classiques</strong> comme les sondages puisque <strong>de nos jours, une partie croissante des consommateurs partage fréquemment leurs opinions sur les réseaux sociaux</strong>. </p>\n",
    "\n",
    "<p><i><strong>Objectif :</strong></i> Le but de notre projet est donc de mettre en place un modèle permettant de classifier les différents avis des clients d’un hôtel en deux classes qui sont : Avis positifs et avis négatifs.<br>\n",
    "Cette classification permettra au personnel de l’hôtel de pouvoir identifier les principales plaintes (Texte négatifs) afin d’améliorer leurs services et réduire le niveau d’insatisfaction des clients.<br></p>\n",
    "\n",
    "<h3><li>Constitution de la dataset</h3></li>\n",
    "<p>Avant d’entamer le travail proprement dit, nous allons d’abord décrire brièvement notre dataset.<br>\n",
    "Nous avons utilisé une dataset téléchargeable sur Kaggle via le lien suivant : \n",
    "<a href=\"https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews\">https://www.kaggle.com/andrewmvd/trip-advisor-hotel-reviews</a><br></p>\n",
    "Elle contient 15 000 lignes et deux colonnes : <br>\n",
    "<ul>\n",
    "    <li>Une colonne Review : qui n’est autre qu’un paragraphe contenant le commentaire de l’utilisateur</li>\n",
    "    <li>Une colonne Rating : qui précise s’il s’agit d’un avis positif ou pas. 1 pour les avis positifs et 0 pour les avis négatifs</li>\n",
    "</ul><br>\n",
    "<p>En affichant le résumé de la dataset, on s’aperçoit qu’elle contient plus d’avis positifs (17000) que d’avis négatifs (3000). Cette différence pourra sans doute influencer le modèle lors de l’entrainement. Ce dernier risque donc d’overfitter sur les avis positifs.</p><br>\n",
    "Pour remédier à cela, nous avons pensé à deux choses :\n",
    "<ul>\n",
    "    <li>Soit réduire le nombre d’avis positifs </li>\n",
    "    <li>Soit faire du webScraping afin d’augmenter le nombre d’avis négatifs.</li>\n",
    "</ul>\n",
    "\n",
    "La première solution nous permettra d’obtenir au finish une dataset d’environ 6000 lignes, ce qui n’est pas du tout approprié pour un problème de NLP.<br>\n",
    "Nous avons donc opté pour la 2ème solution, celle du webScraping.<br>\n",
    "Nous avons scrapper plusieurs sites différents. Les détails du webscraping se trouve dans le notebook <a href=\"scraping_data.py\"> webscraping.ipynb</a>.\n",
    "\n",
    "Ensuite nous avons concaténé les deux dataframes pour n’en faire qu’une seule.<br>\n",
    "//code \n",
    "Une fois que cela est fait, Notre dataset est constitué et on peut enchainer avec les étapes suivantes.<br>\n",
    "<h3><li>Plan de travail</h3></li>\n",
    "Comme on peut s’en douter, Il s’agit ici d’un problème de Natural Language Processing (NLP) ou Traitement automatique du langage naturel.<br>\n",
    "Et comme pour tout problème de NLP, Notre travail se compose principalement de deux parties :\n",
    "\n",
    "<ul>\n",
    "    <li>La partie <b>« linguistique »</b>, qui consiste à prétraiter et transformer les informations en entrée en un jeu de données exploitable.</li>\n",
    "    <li>La partie <b>« apprentissage automatique »</b>, qui porte sur l’application de modèles <b><i>de Machine Learning</i></b> à ce jeu de données.</li><br>\n",
    "</ul>\n",
    "Dans la suite du rapport, Nous allons aborder ces deux aspects, en décrivant brièvement les <b>principales méthodes utilisées </b>et en précisant les principaux défis auxquels nous avons fait face.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol type=\"A\">\n",
    "<h3><li>Partie linguistique : Du texte à la donnée</li></h3>\n",
    "<p>Parmi les principales étapes de cette partie, on retrouve :</p>\n",
    "<ol type=\"a\">\n",
    "<li>Nettoyage : cette phase consiste à réaliser des tâches telles que la <b><i>suppression d’urls, d’emoji, suppression des chiffres, ponctuation, symboles et stopwords, passage en minuscule</i><b>.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_URL\u001b[39m (text):\n\u001b[1;32m      6\u001b[0m     url \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps?://\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+ www\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_URL (text):\n",
    "    url = re.compile(r\"https?://\\s+ www\\.\\s+\")\n",
    "    return url.sub(r\"\", text)\n",
    "\n",
    "\n",
    "def remove_html(text):\n",
    "    html = re.compile(r\"<.*?>\")\n",
    "    return html.sub(r\"\", text)\n",
    "         \n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" # flags (i0s)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", string)\n",
    "\n",
    "\n",
    "def remove_punct (text):\n",
    "    table = str.maketrans (\"\",\"\",string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "stop = set (stopwords.words ( \"english\"))\n",
    "def remove_stopwords (text):\n",
    "    text = [word.lower () for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>On regroupe toutes ses fonctions en une seule appelée ‘nettoyer dataframe’</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyerDataframe(df):\n",
    "    df[\"Review\"] = df.Review.map(lambda x: remove_URL(x))\n",
    "    df[\"Review\"] = df.Review.map(lambda x: remove_html(x))\n",
    "    df[\"Review\"] = df.Review.map(lambda x: remove_emoji(x))\n",
    "    df[\"Review\"] = df.Review.map(lambda x: remove_punct(x)) \n",
    "    df[\"Review\"] = df.Review.map(remove_stopwords)   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol type=\"a\" start=\"2\">\n",
    "<li>Normalisation des données :</li>\n",
    "<b><i>Tokenisation</i></b>, ou découpage du texte en plusieurs pièces appelés tokens.<br>\n",
    "Pour cela, nous utiliserons la méthode des N-grammes.<br>\n",
    "Les N-grammes sont simplement toutes les combinaisons de mots ou de lettres adjacents de longueur n que nous pouvons trouver dans notre texte source. Les ngrammes avec n=1 sont appelés <i>unigrammes</i>. De même, <i>les bigrammes</i>(n=2), les trigrammes (n=3) et ainsi de suite peuvent également être utilisés.\n",
    "<br><br>\n",
    "Les unigrammes ne contiennent généralement pas beaucoup d'informations par rapport aux bigrammes et aux trigrammes. Le principe de base derrière les n-grammes est qu'ils capturent la lettre ou le mot susceptible de suivre le mot donné. Plus le n-gramme est long (n élevé), plus vous devez travailler avec du contexte.\n",
    "<br><br>\n",
    "Dans le cas de notre projet, Nous utiliserons les <b><i>bigrammes</i></b> puisque :\n",
    "<ul>\n",
    "<li>Avec les unigrames, chaque mot est isolé de son contexte. Ce qui rendra sans doute moins efficace notre modéle.</li>\n",
    "<li>L’utilisation des N-grammes avec N>2 conduit à une Memory Error (Mémoire RAM insuffisante).</li>\n",
    "</ul>\n",
    "<br><br>\n",
    "<li> Ensuite, Afin de pouvoir appliquer les méthodes de <i>Machine Learning</i> aux problèmes relatifs au langage naturel, il est indispensable de <i>transformer les données textuelles en données numériques</i>.<br>Pour se faire, Il existe plusieurs approches. L’une d’entre elles que nous utiliserons dans ce projet est celle du TF-IDF (<i>Term Frequency-Inverse Document Frequency</i>). Cette méthode consiste <b>à compter le nombre d’occurrences des tokens</b> présents dans le corpus pour chaque texte, que l’on divise ensuite par le nombre d’occurrences total de ces même tokens dans tout le corpus.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tfidf(df,ngrams):\n",
    "    vect = TfidfVectorizer(ngram_range=ngrams).fit(df[\"Review\"])\n",
    "    X = vect.transform(df[\"Review\"])\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A présent nous allons appliquer toutes ces méthodes à la colonne Review de notre dataset afin de la nettoyer et la convertir en TF-IDF.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tripadvisor_hotel_reviews.csv')\n",
    "\n",
    "df['Rating'] = df['Rating'].map({1:0, 2:0, 3:1, 4:1, 5:1})\n",
    "\n",
    "df = nettoyerDataframe(df)\n",
    "\n",
    "X = tfidf(df,(1,1))\n",
    "\n",
    "y=df['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol type=\"A\" start=\"2\">\n",
    "<h3><li>La phase d'apprentissage: Des données au modèle</li></h3>\n",
    "<p>De manière globale, on peut distinguer <b>3 principales approches NLP</b> : les <b>méthodes basées sur des règles</b>, modèles classiques de Machine Learning et modèles de Deep Learning.</p>\n",
    "<br>\n",
    "<ol type=\"a\">\n",
    "<li>Modèles utilisés</li>\n",
    "<p>Nous utiliserons uniquement les modèles classiques de Machine Learning.<br>Elles mettent généralement en œuvre un modèle <b>statistique d’apprentissage automatique</b> tels que ceux de <b>Naive Bayes</b>, de <b>Régression Logistique</b>, <b>SVM</b>.\n",
    "<br><br>\n",
    "Nous utiliserons les trois modèles précités et nous ferons une comparaison des résultats.<br><br>\n",
    "Mais avant cela, Il est nécessaire de subdiviser son jeu de données en jeu d’entrainement et de test.</p>\n",
    "</ol>\n",
    "\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ensuite on instancie le modèle, on l’entraîne, on prédit les résultats sur le jeu de test, puis on évalue la performance à l’aide de quelques métriques.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol type=\"a\" start=\"2\">\n",
    "<li>Métriques d’évaluation </li>\n",
    "<br>\n",
    "Après, Donc, afin d'évaluer les modèles de classification, nous discuterons de ces métriques en détail :\n",
    "<ul>\n",
    "<li>Précision</li>\n",
    "<li>Précision et rappel</li>\n",
    "<li>Score F1</li>\n",
    "</ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Regression logistique</h5>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegression = LogisticRegression(multi_class='multinomial')\n",
    "logisticRegression.fit(X_train, y_train)\n",
    "y_pred = logisticRegression.predict(X_test)\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : Regression logistique ******\")\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print (f\"Score: {f1score * 100} %\") \n",
    "print(f\"Accuracy : {accuracy * 100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Naive Bayes</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussianNB = GaussianNB()\n",
    "gaussianNB.fit(X_train.toarray(),y_train)\n",
    "\n",
    "y_pred = logisticRegression.predict(X_test)\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : Naives Bayes ******\")\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print (f\"Score: {f1score * 100} %\") \n",
    "print(f\"Accuracy : {accuracy * 100} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>SVM</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svmModel = svm.SVC(kernel='linear') # Linear Kernel\n",
    "svmModel.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svmModel.predict(X_test)\n",
    "print(\"\\n***** Métriques d'évaluation : SVM ******\")\n",
    "f1score = f1_score(y_test, y_pred, average='micro')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print (f\"Score: {f1score * 100} %\") \n",
    "print(f\"Accuracy : {accuracy * 100} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Validation croisée (uniquement pour la regression logiqtique) :</h4>\n",
    "<br>\n",
    "Supposons que nous n'avons pas beaucoup de données, et cela n'a pas de sens de diviser nos données en train, validation et test. Sklearn a un objet cross_val_score qui nous permet de voir dans quelle mesure notre modèle se généralise.<br>\n",
    "Nous allons donc l’appliquer sur notre dataset sans la diviser en jeu de données et de tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(logisticRegression, X, df[\"Rating\"], cv=10)\n",
    "\n",
    "print('Cross-Validation Accuracy Scores', scores)\n",
    "scores = pd.Series(scores)\n",
    "print(scores.min())\n",
    "print(scores.mean())\n",
    "print(scores.max())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02a3c894954291fda4ab19733d35c869283f9a77a2dca789b03614318f65231a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('workshop': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
