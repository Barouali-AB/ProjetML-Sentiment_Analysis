{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "#df['Rating'] = df['Rating'].map({1:0, 2:0, 3:1, 4:1, 5:1})\n",
    "\n",
    "df.to_csv('data.csv', index=False)  \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_URL (text):\n",
    "    url = re.compile(r\"https?://\\s+ www\\.\\s+\")\n",
    "    return url.sub(r\"\", text)\n",
    "\n",
    "\n",
    "def remove_html(text):\n",
    "    html = re.compile(r\"<.*?>\")\n",
    "    return html.sub(r\"\", text)\n",
    "         \n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\" # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\" # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\" # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" # flags (i0s)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    return emoji_pattern.sub(r\"\", string)\n",
    "\n",
    "\n",
    "def remove_punct (text):\n",
    "    table = str.maketrans (\"\",\"\",string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "stop = set (stopwords.words ( \"english\"))\n",
    "def remove_stopwords (text):\n",
    "    text = [word.lower () for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nettoyerDataframe(df):\n",
    "    Review_cleaned = df.Review.map(lambda x: remove_URL(x))\n",
    "    Review_cleaned = Review_cleaned.map(lambda x: remove_html(x))\n",
    "    Review_cleaned = Review_cleaned.map(lambda x: remove_emoji(x))\n",
    "    Review_cleaned = Review_cleaned.map(lambda x: remove_punct(x)) \n",
    "    Review_cleaned = Review_cleaned.map(remove_stopwords)   \n",
    "    df.insert(1, \"Review_cleaned\", Review_cleaned)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nettoyerDataframe(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(df.Review_cleaned)\n",
    "\n",
    "[ x for x in X.todense()[0][0:].tolist()[0] if x != 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "\n",
    "def afficherMetriques(y_test,y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f\"Accuracy : {accuracy * 100} %\")\n",
    "    print (f\"Précision {precision * 100} %\") \n",
    "    print (f\"Recall {recall * 100} %\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"Rating\"].values\n",
    "\n",
    "X_train , X_test , y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegression = LogisticRegression(multi_class='multinomial')\n",
    "logisticRegression.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logisticRegression.predict(X_test)\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : Regression logistique ******\")\n",
    "afficherMetriques(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naives Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gaussianNB = GaussianNB()\n",
    "gaussianNB.fit(X_train.toarray(),y_train)\n",
    "\n",
    "y_pred = logisticRegression.predict(X_test)\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : Naives Bayes ******\")\n",
    "afficherMetriques(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "\n",
    "svmModel = svm.SVC(kernel='linear') # Linear Kernel\n",
    "svmModel.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svmModel.predict(X_test)\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : SVM ******\")\n",
    "afficherMetriques(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "pac = PassiveAggressiveClassifier()\n",
    "pac.fit(X_train, y_train)\n",
    "\n",
    "ypred = pac.predict(X_test)\n",
    "\n",
    "print(\"\\n***** Métriques d'évaluation : PAC ******\")\n",
    "afficherMetriques(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation croisée sur le modèle de regression logfistique\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rappels = cross_val_score(logisticRegression, X,y, cv=10,scoring='recall')\n",
    "rappels = pd.Series(rappels)\n",
    "print(\"Rappels : min=\",rappels.min(),\"  max=\",rappels.max(),\"  moyenne=\",rappels.mean())\n",
    "\n",
    "precisions = cross_val_score(logisticRegression, X,y, cv=10,scoring='precision')\n",
    "precisions = pd.Series(precisions)\n",
    "print(\"Precisions : min=\",precisions.min(),\"  max=\",precisions.max(),\"  moyenne=\",precisions.mean())\n",
    "\n",
    "accuracys = cross_val_score(logisticRegression, X,y, cv=10,scoring='accuracy')\n",
    "accuracys = pd.Series(accuracys)\n",
    "print(\"Accuracy : min=\",accuracys.min(),\"  max=\",accuracys.max(),\"  moyenne=\",accuracys.mean())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
